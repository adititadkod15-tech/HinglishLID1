{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyODwYaage5gWLc4aJ18jjxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adititadkod15-tech/HinglishLID1/blob/main/Akasharmukha_transliteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-transliteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89JhzKVjVbmg",
        "outputId": "53eeb6a1-8bae-48f6-eee0-f50d5437c6c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-transliteration\n",
            "  Downloading indic_transliteration-2.3.75-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting backports.functools-lru-cache (from indic-transliteration)\n",
            "  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (2025.11.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.20.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Collecting roman (from indic-transliteration)\n",
            "  Downloading roman-5.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (8.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (4.15.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n",
            "Downloading indic_transliteration-2.3.75-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n",
            "Downloading roman-5.2-py3-none-any.whl (6.0 kB)\n",
            "Installing collected packages: roman, backports.functools-lru-cache, indic-transliteration\n",
            "Successfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.75 roman-5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ySI0DN-U0Xp",
        "outputId": "3ffa7b5e-e5f2-4f60-90ab-47c9ad53589e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Hinglish_data3 (1).txt...\n",
            "Processing 7155 lines on A100...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100/7155 lines\n",
            "Processed 200/7155 lines\n",
            "Processed 300/7155 lines\n",
            "Processed 400/7155 lines\n",
            "Processed 500/7155 lines\n",
            "Processed 600/7155 lines\n",
            "Processed 700/7155 lines\n",
            "Processed 800/7155 lines\n",
            "Processed 900/7155 lines\n",
            "Processed 1000/7155 lines\n",
            "Processed 1100/7155 lines\n",
            "Processed 1200/7155 lines\n",
            "Processed 1300/7155 lines\n",
            "Processed 1400/7155 lines\n",
            "Processed 1500/7155 lines\n",
            "Processed 1600/7155 lines\n",
            "Processed 1700/7155 lines\n",
            "Processed 1800/7155 lines\n",
            "Processed 1900/7155 lines\n",
            "Processed 2000/7155 lines\n",
            "Processed 2100/7155 lines\n",
            "Processed 2200/7155 lines\n",
            "Processed 2300/7155 lines\n",
            "Processed 2400/7155 lines\n",
            "Processed 2500/7155 lines\n",
            "Processed 2600/7155 lines\n",
            "Processed 2700/7155 lines\n",
            "Processed 2800/7155 lines\n",
            "Processed 2900/7155 lines\n",
            "Processed 3000/7155 lines\n",
            "Processed 3100/7155 lines\n",
            "Processed 3200/7155 lines\n",
            "Processed 3300/7155 lines\n",
            "Processed 3400/7155 lines\n",
            "Processed 3500/7155 lines\n",
            "Processed 3600/7155 lines\n",
            "Processed 3700/7155 lines\n",
            "Processed 3800/7155 lines\n",
            "Processed 3900/7155 lines\n",
            "Processed 4000/7155 lines\n",
            "Processed 4100/7155 lines\n",
            "Processed 4200/7155 lines\n",
            "Processed 4300/7155 lines\n",
            "Processed 4400/7155 lines\n",
            "Processed 4500/7155 lines\n",
            "Processed 4600/7155 lines\n",
            "Processed 4700/7155 lines\n",
            "Processed 4800/7155 lines\n",
            "Processed 4900/7155 lines\n",
            "Processed 5000/7155 lines\n",
            "Processed 5100/7155 lines\n",
            "Processed 5200/7155 lines\n",
            "Processed 5300/7155 lines\n",
            "Processed 5400/7155 lines\n",
            "Processed 5500/7155 lines\n",
            "Processed 5600/7155 lines\n",
            "Processed 5700/7155 lines\n",
            "Processed 5800/7155 lines\n",
            "Processed 5900/7155 lines\n",
            "Processed 6000/7155 lines\n",
            "Processed 6100/7155 lines\n",
            "Processed 6200/7155 lines\n",
            "Processed 6300/7155 lines\n",
            "Processed 6400/7155 lines\n",
            "Processed 6500/7155 lines\n",
            "Processed 6600/7155 lines\n",
            "Processed 6700/7155 lines\n",
            "Processed 6800/7155 lines\n",
            "Processed 6900/7155 lines\n",
            "Processed 7000/7155 lines\n",
            "Processed 7100/7155 lines\n",
            "\n",
            "Success! File saved as: mixed_hinglish_output.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "import re\n",
        "\n",
        "# 1. Initialize LID Pipeline on GPU\n",
        "lid_pipeline = pipeline(\"token-classification\", model=\"l3cube-pune/hing-bert-lid\", device=0)\n",
        "\n",
        "def make_actual_hinglish(sentence):\n",
        "    if not sentence.strip():\n",
        "        return \"\"\n",
        "\n",
        "    # Run LID\n",
        "    results = lid_pipeline(sentence)\n",
        "\n",
        "    # Reconstruct tokens\n",
        "    words_data = []\n",
        "    current_word, current_label = \"\", \"\"\n",
        "    for entity in results:\n",
        "        raw_word = entity['word']\n",
        "        label = entity['entity']\n",
        "        if raw_word.startswith(\"##\"):\n",
        "            current_word += raw_word.replace(\"##\", \"\")\n",
        "        else:\n",
        "            if current_word: words_data.append((current_word, current_label))\n",
        "            current_word, current_label = raw_word, label\n",
        "    if current_word: words_data.append((current_word, current_label))\n",
        "\n",
        "    # Transliterate ONLY Hindi words\n",
        "    mixed_words = []\n",
        "    for word, label in words_data:\n",
        "        if label == 'HI':\n",
        "            # Remove symbols/numbers for the transliteration engine\n",
        "            clean_word = re.sub(r'[^a-zA-Z]', '', word)\n",
        "            if clean_word:\n",
        "                hindi_script = transliterate(clean_word.lower(), sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "                mixed_words.append(hindi_script)\n",
        "            else:\n",
        "                mixed_words.append(word)\n",
        "        else:\n",
        "            # Keep English and Punctuation as is\n",
        "            mixed_words.append(word)\n",
        "\n",
        "    return \" \".join(mixed_words)\n",
        "\n",
        "# 2. Read your .txt file and process\n",
        "input_file = \"/content/Hinglish_data3 (1).txt\"  # <-- Change this to your uploaded file name\n",
        "output_file = \"mixed_hinglish_output.txt\"\n",
        "\n",
        "print(f\"Reading {input_file}...\")\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(f\"Processing {len(lines)} lines on A100...\")\n",
        "\n",
        "processed_lines = []\n",
        "for i, line in enumerate(lines):\n",
        "    converted = make_actual_hinglish(line.strip())\n",
        "    processed_lines.append(converted)\n",
        "\n",
        "    # Progress update every 100 lines\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(lines)} lines\")\n",
        "\n",
        "# 3. Save the results\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    for line in processed_lines:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "print(f\"\\nSuccess! File saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aksharamukha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reS2ppQhWA5N",
        "outputId": "8b05fa41-141c-418e-cc92-83ac11c7c3b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aksharamukha\n",
            "  Downloading aksharamukha-2.3-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Requests>=2.20.1 in /usr/local/lib/python3.12/dist-packages (from aksharamukha) (2.32.4)\n",
            "Collecting pykakasi>=2.0.6 (from aksharamukha)\n",
            "  Downloading pykakasi-2.3.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from aksharamukha) (6.0.3)\n",
            "Collecting langcodes>=3.1.0 (from aksharamukha)\n",
            "  Downloading langcodes-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting language-data (from aksharamukha)\n",
            "  Downloading language_data-1.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from aksharamukha) (2025.11.3)\n",
            "Requirement already satisfied: fonttools>=4.27 in /usr/local/lib/python3.12/dist-packages (from fonttools[unicode]>=4.27->aksharamukha) (4.61.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from aksharamukha) (6.0.2)\n",
            "Collecting unicodedata2>=17.0.0 (from fonttools[unicode]>=4.27->aksharamukha)\n",
            "  Downloading unicodedata2-17.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting jaconv (from pykakasi>=2.0.6->aksharamukha)\n",
            "  Downloading jaconv-0.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting deprecated (from pykakasi>=2.0.6->aksharamukha)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from Requests>=2.20.1->aksharamukha) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from Requests>=2.20.1->aksharamukha) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from Requests>=2.20.1->aksharamukha) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from Requests>=2.20.1->aksharamukha) (2025.11.12)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data->aksharamukha)\n",
            "  Downloading marisa_trie-1.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->pykakasi>=2.0.6->aksharamukha) (2.0.1)\n",
            "Downloading aksharamukha-2.3-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pykakasi-2.3.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_data-1.4.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m140.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marisa_trie-1.3.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unicodedata2-17.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (531 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.0/532.0 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading jaconv-0.4.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: unicodedata2, jaconv, marisa-trie, langcodes, deprecated, pykakasi, language-data, aksharamukha\n",
            "Successfully installed aksharamukha-2.3 deprecated-1.3.1 jaconv-0.4.1 langcodes-3.5.1 language-data-1.4.0 marisa-trie-1.3.1 pykakasi-2.3.0 unicodedata2-17.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aksharamukha import transliterate"
      ],
      "metadata": {
        "id": "WLjqJtq7bmII"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_and_phonemize(text):\n",
        "    clean_hindi = text.replace('् ', ' ').replace('्.', '.')\n",
        "    if clean_hindi.endswith('्'):\n",
        "        clean_hindi = clean_hindi[:-1]\n",
        "\n",
        "    # STEP 2: Convert to Roman Hinglish (keeping English intact)\n",
        "    # Aksharamukha's 'RomanColloquial' is best for readable Roman Hindi\n",
        "    roman_hinglish = transliterate.process('Devanagari', 'RomanColloquial', clean_hindi)\n",
        "\n",
        "    # STEP 3: Generate Phonemes (IPA)\n",
        "    # We use the 'IPA' target which is built specifically for phonetic accuracy\n",
        "    phonemes = transliterate.process('Devanagari', 'IPA', clean_hindi)\n",
        "\n",
        "    return clean_hindi, roman_hinglish, phonemes"
      ],
      "metadata": {
        "id": "E4tzyXqYbp9g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aksharamukha import transliterate\n",
        "\n",
        "def process_with_clean_spelling(text):\n",
        "    # 1. First, fix your dataset's trailing halants (्)\n",
        "    clean_devanagari = text.replace('् ', ' ').replace('्.', '.')\n",
        "    if clean_devanagari.endswith('्'):\n",
        "        clean_devanagari = clean_devanagari[:-1]\n",
        "\n",
        "    # 2. CONVERT TO ROMAN HINDI (With Schwa Deletion enabled)\n",
        "    # This acts as a spellcheck to remove the 'a' from the end of words like 'baat'\n",
        "    roman_clean = transliterate.process('Devanagari', 'RomanColloquial', clean_devanagari,\n",
        "                                        pre_options=['RemoveSchwaHindi'])\n",
        "\n",
        "    # 3. GET IPA PHONEMES (Also with Schwa Deletion)\n",
        "    ipa_clean = transliterate.process('Devanagari', 'IPA', clean_devanagari,\n",
        "                                      pre_options=['RemoveSchwaHindi'])\n",
        "\n",
        "    return roman_clean, ipa_clean\n",
        "\n",
        "# --- Testing with your sentence ---\n",
        "sample_sentences = ['आज् कि इस् roundtable discussion क मुख्य् विशय् बहुत् हि भवुक् है ( 999 words ) - wars और् conflicts के emotional असर् पर् चर्च कर्नि hai . ये एक् ऐसि चीज़् है जो हर् इन्सान् को छू कर् जाति है , चहे वोह् उस्मेइन् directly शामिल् हो य न ho .',\n",
        "                    'पह्ले तोह् हुम् बात् कर्ते हैन् cambodian civil war कि ( 999 words ) . वहन् पर् जो हुअ , वोह् सच् मेइन् heartache और् शोक् से भर tha . लखोन् लोगोन् कि ज़िन्दगियन् बर्बद् हो गयिहि . कित्नि हि औरतेन् विध्वा हो गयिहि , और् कित्ने बच्चे अनथ् ! सब् के चेह्रोन् पर् सिर्फ़् निरश और् melancholic हि नज़र् आत होग उस् समय् .',\n",
        "                    'मुझे याद् है जब् मैने एक् documentary देख थ इस् war के बारे mein . वोह् सब् सुन्कर् मेर रूह् कान्प् गय tha . बच्चोन् को अप्ने मा - बाप् को खोते देख्न , औरतोन् कि विध्ववस्थ , ये सब् देख्कर् एक्दुम् से मेर मन् उदास् और् dismay से भर् गय tha .',\n",
        "                    'जैस कि आप् सब् जान्ते हैन् , wars के beech chemical और् biological weapons क इस्तेमाल् भि होत hai . इन्से तोह् और् भि नुक्सन् होत है ज़िन्दगियोन् ka . एक् missile य bomb से लखोन् लोग् दुखि हो जाते हैन् - अप्ने घर् गवा देते हैन् , अप्ने परिवार् को खा देते hain . ये सब् सोच्न हि इत्न हिदायथीन् कर्त hai .',\n",
        "                    'fijian coups के बारे मेइन् पध थ मैने कुच् दिनो पेह्ले . वहन् पर् भि बहुत् कुछ् हुअ tha . आखिर् क्युन् होति हैन् ये सब् चीज़ेइन् ? क्युन् कोइ उसे bombs और् weapons कर्त है दूस्रे कि ज़िन्दगियोन् को बर्बद् कर्ने के लिये ? ये सब् जान्ने के बाद् तोह् मैन् एक्दुम् हि निम्हन्स् हो गय tha .',\n",
        "                    'और् जैस कि हुम् जान्ते हैन् , india भि ऐसे हि कयि wars और् insurgencies से गुज़्र hai . जैसे कि naxalite - maoist insurgency , और् eritrean war of independence . in दोनो मेइन् कित्ने हि जवान् शहीद् हुए , और् कित्ने गरीब् लोगोन् को अप्नि ज़िन्दगियान् गवनि पदिन् . सब् के घर् बर्बद् हो gaye , सरि उमीदेन् तूत् गयिहि .']\n",
        "for sample in sample_sentences:\n",
        "  roman, ipa = process_with_clean_spelling(sample)\n",
        "\n",
        "  print(f\"hinglish:{sample}\")\n",
        "  print(f\"Clean Roman: {roman}\")\n",
        "  print(f\"Clean IPA:   {ipa}\")\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PS80wTOWyz2",
        "outputId": "060268d2-2c8f-4b72-9f87-1e9087d8ceab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hinglish:आज् कि इस् roundtable discussion क मुख्य् विशय् बहुत् हि भवुक् है ( 999 words ) - wars और् conflicts के emotional असर् पर् चर्च कर्नि hai . ये एक् ऐसि चीज़् है जो हर् इन्सान् को छू कर् जाति है , चहे वोह् उस्मेइन् directly शामिल् हो य न ho .\n",
            "Clean Roman: aj ki is roundtable discussion ka mukhya vishay bahut hi bhavuk hai ( 999 words ) - wars aur conflicts ke emotional asar par charch karni hai . ye ek aisi chiz hai jo har insan ko chhu kar jati hai , chahe voh usmein directly shamil ho ya na ho .\n",
            "Clean IPA:   ɑːd͡ʒ kɪ ɪs̪ roundtable discussion kə mukʰjə ʋɪʃəj bəɦut̪ ɦɪ bʰəʋuk ɦəɪ ( 999 words ) - wars əuɾ conflicts keː emotional əs̪əɾ pəɾ t͡ʃəɾt͡ʃ kəɾn̪ɪ h ̆ai . jeː eːk əɪs̪ɪ t͡ʃiːz ɦəɪ d͡ʒoː ɦəɾ ɪn̪s̪ɑːn̪ koː t͡ʃʰuː kəɾ d͡ʒɑːt̪ɪ ɦəɪ , t͡ʃəɦeː ʋoːɦ us̪meːɪn̪ directly ʃɑːmɪl ɦoː jə n̪ə h ̆o .\n",
            "\n",
            "\n",
            "hinglish:पह्ले तोह् हुम् बात् कर्ते हैन् cambodian civil war कि ( 999 words ) . वहन् पर् जो हुअ , वोह् सच् मेइन् heartache और् शोक् से भर tha . लखोन् लोगोन् कि ज़िन्दगियन् बर्बद् हो गयिहि . कित्नि हि औरतेन् विध्वा हो गयिहि , और् कित्ने बच्चे अनथ् ! सब् के चेह्रोन् पर् सिर्फ़् निरश और् melancholic हि नज़र् आत होग उस् समय् .\n",
            "Clean Roman: pahle toh hum bat karte hain cambodian civil war ki ( 999 words ) . vahan par jo hua , voh sach mein heartache aur shok se bhar tha . lakhon logon ki zindagiyan barbad ho gayihi . kitni hi aurten vidhva ho gayihi , aur kitne bachche anath ! sab ke chehron par sirfa nirash aur melancholic hi nazar at hog us samay .\n",
            "Clean IPA:   pəɦleː t̪oːɦ ɦum bɑːt̪ kəɾt̪eː ɦəɪn̪ cambodian civil war kɪ ( 999 words ) . ʋəɦən̪ pəɾ d͡ʒoː ɦuə , ʋoːɦ s̪ət͡ʃ meːɪn̪ h ̆eartachc̆e əuɾ ʃoːk s̪eː bʰəɾ tht̆a . ləkʰoːn̪ loːgoːn̪ kɪ zɪn̪d̪əgɪjən̪ bəɾbəd̪ ɦoː gəjɪɦɪ . kɪt̪n̪ɪ ɦɪ əuɾt̪eːn̪ ʋɪd̪ʰʋɑː ɦoː gəjɪɦɪ , əuɾ kɪt̪n̪eː bət͡ʃt͡ʃeː ən̪ət̪ʰ ! s̪əb keː t͡ʃeːɦɾoːn̪ pəɾ s̪ɪɾfə n̪ɪɾəʃ əuɾ melanchc̆olic ɦɪ n̪əzəɾ ɑːt̪ ɦoːg us̪ s̪əməj .\n",
            "\n",
            "\n",
            "hinglish:मुझे याद् है जब् मैने एक् documentary देख थ इस् war के बारे mein . वोह् सब् सुन्कर् मेर रूह् कान्प् गय tha . बच्चोन् को अप्ने मा - बाप् को खोते देख्न , औरतोन् कि विध्ववस्थ , ये सब् देख्कर् एक्दुम् से मेर मन् उदास् और् dismay से भर् गय tha .\n",
            "Clean Roman: mujhe yad hai jab maine ek documentary dekh tha is war ke bare mein . voh sab sunkar mer ruh kanp gay tha . bachchon ko apne ma - bap ko khote dekhna , aurton ki vidhvavasth , ye sab dekhkar ekdum se mer man udas aur dismay se bhar gay tha .\n",
            "Clean IPA:   mud͡ʒʰeː jɑːd̪ ɦəɪ d͡ʒəb məɪn̪eː eːk documentary d̪eːkʰ t̪ʰə ɪs̪ war keː bɑːɾeː mein . ʋoːɦ s̪əb s̪un̪kəɾ meːɾ ɾuːɦ kɑːn̪p gəj tht̆a . bət͡ʃt͡ʃoːn̪ koː əpn̪eː mɑː - bɑːp koː kʰoːt̪eː d̪eːkʰn̪ə , əuɾt̪oːn̪ kɪ ʋɪd̪ʰʋəʋəs̪t̪ʰ , jeː s̪əb d̪eːkʰkəɾ eːkd̪um s̪eː meːɾ mən̪ ud̪ɑːs̪ əuɾ dismay s̪eː bʰəɾ gəj tht̆a .\n",
            "\n",
            "\n",
            "hinglish:जैस कि आप् सब् जान्ते हैन् , wars के beech chemical और् biological weapons क इस्तेमाल् भि होत hai . इन्से तोह् और् भि नुक्सन् होत है ज़िन्दगियोन् ka . एक् missile य bomb से लखोन् लोग् दुखि हो जाते हैन् - अप्ने घर् गवा देते हैन् , अप्ने परिवार् को खा देते hain . ये सब् सोच्न हि इत्न हिदायथीन् कर्त hai .\n",
            "Clean Roman: jais ki ap sab jante hain , wars ke beech chemical aur biological weapons ka istemal bhi hot hai . inse toh aur bhi nuksan hot hai zindagiyon ka . ek missile ya bomb se lakhon log dukhi ho jate hain - apne ghar gava dete hain , apne parivar ko kha dete hain . ye sab sochna hi itna hidaythin kart hai .\n",
            "Clean IPA:   d͡ʒəɪs̪ kɪ ɑːp s̪əb d͡ʒɑːn̪t̪eː ɦəɪn̪ , wars keː beechc̆ chc̆emical əuɾ biological weapons kə ɪs̪t̪eːmɑːl bʰɪ ɦoːt̪ h ̆ai . ɪn̪s̪eː t̪oːɦ əuɾ bʰɪ n̪uks̪ən̪ ɦoːt̪ ɦəɪ zɪn̪d̪əgɪjoːn̪ ka . eːk missile jə bomb s̪eː ləkʰoːn̪ loːg d̪ukʰɪ ɦoː d͡ʒɑːt̪eː ɦəɪn̪ - əpn̪eː gʰəɾ gəʋɑː d̪eːt̪eː ɦəɪn̪ , əpn̪eː pəɾɪʋɑːɾ koː kʰɑː d̪eːt̪eː h ̆ain . jeː s̪əb s̪oːt͡ʃn̪ə ɦɪ ɪt̪n̪ə ɦɪd̪ɑːjt̪ʰiːn̪ kəɾt̪ h ̆ai .\n",
            "\n",
            "\n",
            "hinglish:fijian coups के बारे मेइन् पध थ मैने कुच् दिनो पेह्ले . वहन् पर् भि बहुत् कुछ् हुअ tha . आखिर् क्युन् होति हैन् ये सब् चीज़ेइन् ? क्युन् कोइ उसे bombs और् weapons कर्त है दूस्रे कि ज़िन्दगियोन् को बर्बद् कर्ने के लिये ? ये सब् जान्ने के बाद् तोह् मैन् एक्दुम् हि निम्हन्स् हो गय tha .\n",
            "Clean Roman: fijian coups ke bare mein padh tha maine kuch dino pehle . vahan par bhi bahut kuchh hua tha . akhir kyun hoti hain ye sab chizein ? kyun koi use bombs aur weapons kart hai dusre ki zindagiyon ko barbad karne ke liye ? ye sab janne ke bad toh main ekdum hi nimhans ho gay tha .\n",
            "Clean IPA:   fijian coups keː bɑːɾeː meːɪn̪ pəd̪ʰ t̪ʰə məɪn̪eː kut͡ʃ d̪ɪn̪oː peːɦleː . ʋəɦən̪ pəɾ bʰɪ bəɦut̪ kut͡ʃʰ ɦuə tht̆a . ɑːkʰɪɾ kjun̪ ɦoːt̪ɪ ɦəɪn̪ jeː s̪əb t͡ʃiːzeːɪn̪ ? kjun̪ koːɪ us̪eː bombs əuɾ weapons kəɾt̪ ɦəɪ d̪uːs̪ɾeː kɪ zɪn̪d̪əgɪjoːn̪ koː bəɾbəd̪ kəɾn̪eː keː lɪjeː ? jeː s̪əb d͡ʒɑːn̪n̪eː keː bɑːd̪ t̪oːɦ məɪn̪ eːkd̪um ɦɪ n̪ɪmɦən̪s̪ ɦoː gəj tht̆a .\n",
            "\n",
            "\n",
            "hinglish:और् जैस कि हुम् जान्ते हैन् , india भि ऐसे हि कयि wars और् insurgencies से गुज़्र hai . जैसे कि naxalite - maoist insurgency , और् eritrean war of independence . in दोनो मेइन् कित्ने हि जवान् शहीद् हुए , और् कित्ने गरीब् लोगोन् को अप्नि ज़िन्दगियान् गवनि पदिन् . सब् के घर् बर्बद् हो gaye , सरि उमीदेन् तूत् गयिहि .\n",
            "Clean Roman: aur jais ki hum jante hain , india bhi aise hi kayi wars aur insurgencies se guzra hai . jaise ki naxalite - maoist insurgency , aur eritrean war of independence . in dono mein kitne hi javan shahid hue , aur kitne garib logon ko apni zindagiyan gavni padin . sab ke ghar barbad ho gaye , sari umiden tut gayihi .\n",
            "Clean IPA:   əuɾ d͡ʒəɪs̪ kɪ ɦum d͡ʒɑːn̪t̪eː ɦəɪn̪ , india bʰɪ əɪs̪eː ɦɪ kəjɪ wars əuɾ insurgencies s̪eː guzɾə h ̆ai . d͡ʒəɪs̪eː kɪ naxalite - maoist insurgency , əuɾ eritrean war of independence . in d̪oːn̪oː meːɪn̪ kɪt̪n̪eː ɦɪ d͡ʒəʋɑːn̪ ʃəɦiːd̪ ɦueː , əuɾ kɪt̪n̪eː gəɾiːb loːgoːn̪ koː əpn̪ɪ zɪn̪d̪əgɪjɑːn̪ gəʋn̪ɪ pəd̪ɪn̪ . s̪əb keː gʰəɾ bəɾbəd̪ ɦoː gaye , s̪əɾɪ umiːd̪eːn̪ t̪uːt̪ gəjɪɦɪ .\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-nlp-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "MnEiWEascSqO",
        "outputId": "e1cec6a4-eadd-478e-a276-853f871803a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.3)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.4)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.11.12)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              },
              "id": "39b67ce0b54b40879638ef1a64268c03"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aksharamukha import transliterate\n",
        "from indicnlp.normalize.indic_normalize import DevanagariNormalizer\n",
        "\n",
        "# Initialize the Normalizer\n",
        "normalizer = DevanagariNormalizer()\n",
        "\n",
        "def  process_with_clean_spelling(text):\n",
        "    # 1. CLEAN THE DATASET ARTIFACTS\n",
        "    # Remove the trailing halants you mentioned earlier\n",
        "    text = text.replace('् ', ' ').replace('्.', '.')\n",
        "\n",
        "    # 2. HINDI SPELLCHECK/NORMALIZATION\n",
        "    # This fixes character-level spelling mistakes\n",
        "    normalized_text = normalizer.normalize(text)\n",
        "\n",
        "    # 3. TRANSLITERATE TO ROMAN\n",
        "    # We use 'pre_options' to delete schwas and 'post_options' to ensure long vowels\n",
        "    roman = transliterate.process('Devanagari', 'RomanColloquial', normalized_text,\n",
        "                                  pre_options=['RemoveSchwaHindi'])\n",
        "\n",
        "    # Quick fix for the 'baat/bat' issue:\n",
        "    # Usually 'bat' is mapped to 'baat' in common Hinglish\n",
        "    roman = roman.replace(' bat ', ' baat ').replace(' pahle ', ' pahale ')\n",
        "\n",
        "    # 4. GET IPA PHONEMES\n",
        "    ipa = transliterate.process('Devanagari', 'IPA', normalized_text,\n",
        "                                pre_options=['RemoveSchwaHindi'])\n",
        "\n",
        "    return roman, ipa\n",
        "\n",
        "# --- TEST ---\n",
        "sample_sentences = ['आज् कि इस् roundtable discussion क मुख्य् विशय् बहुत् हि भवुक् है ( 999 words ) - wars और् conflicts के emotional असर् पर् चर्च कर्नि hai . ये एक् ऐसि चीज़् है जो हर् इन्सान् को छू कर् जाति है , चहे वोह् उस्मेइन् directly शामिल् हो य न ho .',\n",
        "                    'पह्ले तोह् हुम् बात् कर्ते हैन् cambodian civil war कि ( 999 words ) . वहन् पर् जो हुअ , वोह् सच् मेइन् heartache और् शोक् से भर tha . लखोन् लोगोन् कि ज़िन्दगियन् बर्बद् हो गयिहि . कित्नि हि औरतेन् विध्वा हो गयिहि , और् कित्ने बच्चे अनथ् ! सब् के चेह्रोन् पर् सिर्फ़् निरश और् melancholic हि नज़र् आत होग उस् समय् .',\n",
        "                    'मुझे याद् है जब् मैने एक् documentary देख थ इस् war के बारे mein . वोह् सब् सुन्कर् मेर रूह् कान्प् गय tha . बच्चोन् को अप्ने मा - बाप् को खोते देख्न , औरतोन् कि विध्ववस्थ , ये सब् देख्कर् एक्दुम् से मेर मन् उदास् और् dismay से भर् गय tha .',\n",
        "                    'जैस कि आप् सब् जान्ते हैन् , wars के beech chemical और् biological weapons क इस्तेमाल् भि होत hai . इन्से तोह् और् भि नुक्सन् होत है ज़िन्दगियोन् ka . एक् missile य bomb से लखोन् लोग् दुखि हो जाते हैन् - अप्ने घर् गवा देते हैन् , अप्ने परिवार् को खा देते hain . ये सब् सोच्न हि इत्न हिदायथीन् कर्त hai .',\n",
        "                    'fijian coups के बारे मेइन् पध थ मैने कुच् दिनो पेह्ले . वहन् पर् भि बहुत् कुछ् हुअ tha . आखिर् क्युन् होति हैन् ये सब् चीज़ेइन् ? क्युन् कोइ उसे bombs और् weapons कर्त है दूस्रे कि ज़िन्दगियोन् को बर्बद् कर्ने के लिये ? ये सब् जान्ने के बाद् तोह् मैन् एक्दुम् हि निम्हन्स् हो गय tha .',\n",
        "                    'और् जैस कि हुम् जान्ते हैन् , india भि ऐसे हि कयि wars और् insurgencies से गुज़्र hai . जैसे कि naxalite - maoist insurgency , और् eritrean war of independence . in दोनो मेइन् कित्ने हि जवान् शहीद् हुए , और् कित्ने गरीब् लोगोन् को अप्नि ज़िन्दगियान् गवनि पदिन् . सब् के घर् बर्बद् हो gaye , सरि उमीदेन् तूत् गयिहि .']\n",
        "for sample in sample_sentences:\n",
        "  roman, ipa = process_with_clean_spelling(sample)\n",
        "\n",
        "  print(f\"hinglish:{sample}\")\n",
        "  print(f\"Clean Roman: {roman}\")\n",
        "  print(f\"Clean IPA:   {ipa}\")\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ETnPUBecuN7",
        "outputId": "e2e6fdb9-d39f-45ff-f242-af1ae59af404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hinglish:आज् कि इस् roundtable discussion क मुख्य् विशय् बहुत् हि भवुक् है ( 999 words ) - wars और् conflicts के emotional असर् पर् चर्च कर्नि hai . ये एक् ऐसि चीज़् है जो हर् इन्सान् को छू कर् जाति है , चहे वोह् उस्मेइन् directly शामिल् हो य न ho .\n",
            "Clean Roman: aj ki is roundtable discussion ka mukhya vishay bahut hi bhavuk hai ( 999 words ) - wars aur conflicts ke emotional asar par charch karni hai . ye ek aisi chiz hai jo har insan ko chhu kar jati hai , chahe voh usmein directly shamil ho ya na ho .\n",
            "Clean IPA:   ɑːd͡ʒ kɪ ɪs̪ roundtable discussion kə mukʰjə ʋɪʃəj bəɦut̪ ɦɪ bʰəʋuk ɦəɪ ( 999 words ) - wars əuɾ conflicts keː emotional əs̪əɾ pəɾ t͡ʃəɾt͡ʃ kəɾn̪ɪ h ̆ai . jeː eːk əɪs̪ɪ t͡ʃiːz ɦəɪ d͡ʒoː ɦəɾ ɪn̪s̪ɑːn̪ koː t͡ʃʰuː kəɾ d͡ʒɑːt̪ɪ ɦəɪ , t͡ʃəɦeː ʋoːɦ us̪meːɪn̪ directly ʃɑːmɪl ɦoː jə n̪ə h ̆o .\n",
            "\n",
            "\n",
            "hinglish:पह्ले तोह् हुम् बात् कर्ते हैन् cambodian civil war कि ( 999 words ) . वहन् पर् जो हुअ , वोह् सच् मेइन् heartache और् शोक् से भर tha . लखोन् लोगोन् कि ज़िन्दगियन् बर्बद् हो गयिहि . कित्नि हि औरतेन् विध्वा हो गयिहि , और् कित्ने बच्चे अनथ् ! सब् के चेह्रोन् पर् सिर्फ़् निरश और् melancholic हि नज़र् आत होग उस् समय् .\n",
            "Clean Roman: pahle toh hum baat karte hain cambodian civil war ki ( 999 words ) . vahan par jo hua , voh sach mein heartache aur shok se bhar tha . lakhon logon ki zindagiyan barbad ho gayihi . kitni hi aurten vidhva ho gayihi , aur kitne bachche anath ! sab ke chehron par sirfa nirash aur melancholic hi nazar at hog us samay .\n",
            "Clean IPA:   pəɦleː t̪oːɦ ɦum bɑːt̪ kəɾt̪eː ɦəɪn̪ cambodian civil war kɪ ( 999 words ) . ʋəɦən̪ pəɾ d͡ʒoː ɦuə , ʋoːɦ s̪ət͡ʃ meːɪn̪ h ̆eartachc̆e əuɾ ʃoːk s̪eː bʰəɾ tht̆a . ləkʰoːn̪ loːgoːn̪ kɪ zɪn̪d̪əgɪjən̪ bəɾbəd̪ ɦoː gəjɪɦɪ . kɪt̪n̪ɪ ɦɪ əuɾt̪eːn̪ ʋɪd̪ʰʋɑː ɦoː gəjɪɦɪ , əuɾ kɪt̪n̪eː bət͡ʃt͡ʃeː ən̪ət̪ʰ ! s̪əb keː t͡ʃeːɦɾoːn̪ pəɾ s̪ɪɾfə n̪ɪɾəʃ əuɾ melanchc̆olic ɦɪ n̪əzəɾ ɑːt̪ ɦoːg us̪ s̪əməj .\n",
            "\n",
            "\n",
            "hinglish:मुझे याद् है जब् मैने एक् documentary देख थ इस् war के बारे mein . वोह् सब् सुन्कर् मेर रूह् कान्प् गय tha . बच्चोन् को अप्ने मा - बाप् को खोते देख्न , औरतोन् कि विध्ववस्थ , ये सब् देख्कर् एक्दुम् से मेर मन् उदास् और् dismay से भर् गय tha .\n",
            "Clean Roman: mujhe yad hai jab maine ek documentary dekh tha is war ke bare mein . voh sab sunkar mer ruh kanp gay tha . bachchon ko apne ma - bap ko khote dekhna , aurton ki vidhvavasth , ye sab dekhkar ekdum se mer man udas aur dismay se bhar gay tha .\n",
            "Clean IPA:   mud͡ʒʰeː jɑːd̪ ɦəɪ d͡ʒəb məɪn̪eː eːk documentary d̪eːkʰ t̪ʰə ɪs̪ war keː bɑːɾeː mein . ʋoːɦ s̪əb s̪un̪kəɾ meːɾ ɾuːɦ kɑːn̪p gəj tht̆a . bət͡ʃt͡ʃoːn̪ koː əpn̪eː mɑː - bɑːp koː kʰoːt̪eː d̪eːkʰn̪ə , əuɾt̪oːn̪ kɪ ʋɪd̪ʰʋəʋəs̪t̪ʰ , jeː s̪əb d̪eːkʰkəɾ eːkd̪um s̪eː meːɾ mən̪ ud̪ɑːs̪ əuɾ dismay s̪eː bʰəɾ gəj tht̆a .\n",
            "\n",
            "\n",
            "hinglish:जैस कि आप् सब् जान्ते हैन् , wars के beech chemical और् biological weapons क इस्तेमाल् भि होत hai . इन्से तोह् और् भि नुक्सन् होत है ज़िन्दगियोन् ka . एक् missile य bomb से लखोन् लोग् दुखि हो जाते हैन् - अप्ने घर् गवा देते हैन् , अप्ने परिवार् को खा देते hain . ये सब् सोच्न हि इत्न हिदायथीन् कर्त hai .\n",
            "Clean Roman: jais ki ap sab jante hain , wars ke beech chemical aur biological weapons ka istemal bhi hot hai . inse toh aur bhi nuksan hot hai zindagiyon ka . ek missile ya bomb se lakhon log dukhi ho jate hain - apne ghar gava dete hain , apne parivar ko kha dete hain . ye sab sochna hi itna hidaythin kart hai .\n",
            "Clean IPA:   d͡ʒəɪs̪ kɪ ɑːp s̪əb d͡ʒɑːn̪t̪eː ɦəɪn̪ , wars keː beechc̆ chc̆emical əuɾ biological weapons kə ɪs̪t̪eːmɑːl bʰɪ ɦoːt̪ h ̆ai . ɪn̪s̪eː t̪oːɦ əuɾ bʰɪ n̪uks̪ən̪ ɦoːt̪ ɦəɪ zɪn̪d̪əgɪjoːn̪ ka . eːk missile jə bomb s̪eː ləkʰoːn̪ loːg d̪ukʰɪ ɦoː d͡ʒɑːt̪eː ɦəɪn̪ - əpn̪eː gʰəɾ gəʋɑː d̪eːt̪eː ɦəɪn̪ , əpn̪eː pəɾɪʋɑːɾ koː kʰɑː d̪eːt̪eː h ̆ain . jeː s̪əb s̪oːt͡ʃn̪ə ɦɪ ɪt̪n̪ə ɦɪd̪ɑːjt̪ʰiːn̪ kəɾt̪ h ̆ai .\n",
            "\n",
            "\n",
            "hinglish:fijian coups के बारे मेइन् पध थ मैने कुच् दिनो पेह्ले . वहन् पर् भि बहुत् कुछ् हुअ tha . आखिर् क्युन् होति हैन् ये सब् चीज़ेइन् ? क्युन् कोइ उसे bombs और् weapons कर्त है दूस्रे कि ज़िन्दगियोन् को बर्बद् कर्ने के लिये ? ये सब् जान्ने के बाद् तोह् मैन् एक्दुम् हि निम्हन्स् हो गय tha .\n",
            "Clean Roman: fijian coups ke bare mein padh tha maine kuch dino pehle . vahan par bhi bahut kuchh hua tha . akhir kyun hoti hain ye sab chizein ? kyun koi use bombs aur weapons kart hai dusre ki zindagiyon ko barbad karne ke liye ? ye sab janne ke bad toh main ekdum hi nimhans ho gay tha .\n",
            "Clean IPA:   fijian coups keː bɑːɾeː meːɪn̪ pəd̪ʰ t̪ʰə məɪn̪eː kut͡ʃ d̪ɪn̪oː peːɦleː . ʋəɦən̪ pəɾ bʰɪ bəɦut̪ kut͡ʃʰ ɦuə tht̆a . ɑːkʰɪɾ kjun̪ ɦoːt̪ɪ ɦəɪn̪ jeː s̪əb t͡ʃiːzeːɪn̪ ? kjun̪ koːɪ us̪eː bombs əuɾ weapons kəɾt̪ ɦəɪ d̪uːs̪ɾeː kɪ zɪn̪d̪əgɪjoːn̪ koː bəɾbəd̪ kəɾn̪eː keː lɪjeː ? jeː s̪əb d͡ʒɑːn̪n̪eː keː bɑːd̪ t̪oːɦ məɪn̪ eːkd̪um ɦɪ n̪ɪmɦən̪s̪ ɦoː gəj tht̆a .\n",
            "\n",
            "\n",
            "hinglish:और् जैस कि हुम् जान्ते हैन् , india भि ऐसे हि कयि wars और् insurgencies से गुज़्र hai . जैसे कि naxalite - maoist insurgency , और् eritrean war of independence . in दोनो मेइन् कित्ने हि जवान् शहीद् हुए , और् कित्ने गरीब् लोगोन् को अप्नि ज़िन्दगियान् गवनि पदिन् . सब् के घर् बर्बद् हो gaye , सरि उमीदेन् तूत् गयिहि .\n",
            "Clean Roman: aur jais ki hum jante hain , india bhi aise hi kayi wars aur insurgencies se guzra hai . jaise ki naxalite - maoist insurgency , aur eritrean war of independence . in dono mein kitne hi javan shahid hue , aur kitne garib logon ko apni zindagiyan gavni padin . sab ke ghar barbad ho gaye , sari umiden tut gayihi .\n",
            "Clean IPA:   əuɾ d͡ʒəɪs̪ kɪ ɦum d͡ʒɑːn̪t̪eː ɦəɪn̪ , india bʰɪ əɪs̪eː ɦɪ kəjɪ wars əuɾ insurgencies s̪eː guzɾə h ̆ai . d͡ʒəɪs̪eː kɪ naxalite - maoist insurgency , əuɾ eritrean war of independence . in d̪oːn̪oː meːɪn̪ kɪt̪n̪eː ɦɪ d͡ʒəʋɑːn̪ ʃəɦiːd̪ ɦueː , əuɾ kɪt̪n̪eː gəɾiːb loːgoːn̪ koː əpn̪ɪ zɪn̪d̪əgɪjɑːn̪ gəʋn̪ɪ pəd̪ɪn̪ . s̪əb keː gʰəɾ bəɾbəd̪ ɦoː gaye , s̪əɾɪ umiːd̪eːn̪ t̪uːt̪ gəjɪɦɪ .\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UXddLGxk4MB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}