{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNSO1laWyR+wKr359oM9j2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adititadkod15-tech/HinglishLID1/blob/main/l3cube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5vawyhyMMX1O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  1. Load the model\n",
        "model_id = \"l3cube-pune/hing-bert-lid\"\n",
        "lid_pipeline = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=model_id,\n",
        "    device=0 # Uses cuda:0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J67C7rZuMnO8",
        "outputId": "8dfa8251-8bab-4381-8047-186b56ef6e17"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_lists_fixed(sentence):\n",
        "    # Manual reconstruction to handle sub-word tokens like '##'\n",
        "    results = lid_pipeline(sentence)\n",
        "\n",
        "    hindi_words = []\n",
        "    english_words = []\n",
        "\n",
        "    current_word = \"\"\n",
        "    current_label = \"\"\n",
        "\n",
        "    for entity in results:\n",
        "        raw_word = entity['word']\n",
        "        label = entity['entity'] # Uses 'HI' and 'EN' as per your debug\n",
        "\n",
        "        if raw_word.startswith(\"##\"):\n",
        "            current_word += raw_word.replace(\"##\", \"\")\n",
        "        else:\n",
        "            if current_word:\n",
        "                if current_label == 'HI':\n",
        "                    hindi_words.append(current_word)\n",
        "                elif current_label == 'EN':\n",
        "                    english_words.append(current_word)\n",
        "\n",
        "            current_word = raw_word\n",
        "            current_label = label\n",
        "\n",
        "    # Save the final word\n",
        "    if current_word:\n",
        "        if current_label == 'HI':\n",
        "            hindi_words.append(current_word)\n",
        "        elif current_label == 'EN':\n",
        "            english_words.append(current_word)\n",
        "\n",
        "    return hindi_words, english_words"
      ],
      "metadata": {
        "id": "-HHxuXKeGI-D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Interactive User Input Loop ---\n",
        "sample_sentences =[\n",
        "    'Pahle toh hum baat karte hain Cambodian Civil War ki (999 words). Wahan par jo hua, woh sach mein heartache aur shok se bhara tha. Lakhon logon ki zindagiyan barbad ho gayihi. Kitni hi auraten vidhvaa ho gayihi, aur kitne bachche anath! Sab ke chehron par sirf nirasha aur melancholic hi nazar aata hoga us samay.',\n",
        "    'Mujhe yaad hai jab maine ek documentary dekha tha is war ke baare mein. Woh sab sunkar mera rooh kaanp gaya tha. Bachchon ko apne maa-baap ko khote dekhna, auraton ki vidhvavastha, ye sab dekhkar ekdum se mera man udaas aur dismay se bhar gaya tha. ',\n",
        "    'Jaisa ki aap sab jaante hain, wars ke beech chemical aur biological weapons ka istemaal bhi hota hai. Inse toh aur bhi nuksan hota hai zindagiyon ka. Ek missile ya bomb se lakhon log dukhi ho jaate hain - apne ghar gawaa dete hain, apne parivaar ko khaa dete hain. Ye sab sochna hi itna hidaayatheen karta hai',\n",
        "    'Aaj ki is roundtable discussion ka mukhy vishay bahut hi bhavuk hai (999 words) - wars aur conflicts ke emotional asar par charcha karni hai. Ye ek aisi cheez hai jo har insaan ko chhoo kar jaati hai, chahe woh usmein directly shaamil ho ya na ho.',\n",
        "    'Fijian Coups ke baare mein padha tha maine kuch dino pehle. Wahan par bhi bahut kuchh hua tha. Aakhir kyun hoti hain ye sab cheezein? Kyun koi use bombs aur weapons karta hai doosre ki zindagiyon ko barbad karne ke liye? Ye sab jaanne ke baad toh main ekdum hi nimhans ho gaya tha.',\n",
        "    'Aur jaisa ki hum jaante hain, India bhi aise hi kayi wars aur insurgencies se guzra hai. Jaise ki Naxalite-Maoist insurgency, aur Eritrean War of Independence. In dono mein kitne hi jawaan shaheed hue, aur kitne gareeb logon ko apni zindagiyaan gawani padin. Sab ke ghar barbad ho gaye, sari umeeden toot gayihi.',\n",
        "    'War politics ke peeche badi wajah ye fear of war hota hai har country ka (999 words). Har koi chahta hai ki unhe jeetna hai, unhe power mein rehna hai. Issi liye ye sab wars shuru hote rehte hain. Par in sab ke peeche, sabse bada nuksan toh aam insaanon ka hi hota hai. '\n",
        "]\n",
        "\n",
        "sample_sentences = [\n",
        "    'hello neevu yen madlikatriki nanu iga malkotini light off madri i am tired '\n",
        "]\n",
        "\n",
        "print(\"--- Hinglish Language Analyzer Ready ---\")\n",
        "print(\"Type 'exit' or 'quit' to stop.\")\n",
        "\n",
        "\n",
        "for sentence in sample_sentences:\n",
        "      print(sentence)\n",
        "      if sentence.lower() in ['exit', 'quit']:\n",
        "          print(\"Exiting...\")\n",
        "          break\n",
        "\n",
        "      if not sentence.strip():\n",
        "          continue\n",
        "\n",
        "      hi, en = get_word_lists_fixed(sentence)\n",
        "\n",
        "      print(\"-\" * 30)\n",
        "      print(f\"Hindi Words:   {hi}\")\n",
        "      print(f\"English Words: {en}\")\n",
        "      print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFY0VFoBGJzY",
        "outputId": "54e76840-45be-4191-dc40-7807319190a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Hinglish Language Analyzer Ready ---\n",
            "Type 'exit' or 'quit' to stop.\n",
            "hello neevu yen madlikatriki nanu iga malkotini light off madri i am tired \n",
            "------------------------------\n",
            "Hindi Words:   ['neevu', 'madlikatriki', 'nanu', 'malkotini', 'madri']\n",
            "English Words: ['hello', 'yen', 'iga', 'light', 'off', 'i', 'am', 'tired']\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGIoZ4rnHHtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TRANSLITERATION**"
      ],
      "metadata": {
        "id": "agcN_kOMI0qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-transliteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9hmT1rI88q",
        "outputId": "866e7b29-770c-480b-b6b6-3ded26c42fc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-transliteration\n",
            "  Downloading indic_transliteration-2.3.75-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting backports.functools-lru-cache (from indic-transliteration)\n",
            "  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (2025.11.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.20.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Collecting roman (from indic-transliteration)\n",
            "  Downloading roman-5.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting click>=8.0.0 (from typer->indic-transliteration)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (4.15.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n",
            "Downloading indic_transliteration-2.3.75-py3-none-any.whl (159 kB)\n",
            "Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n",
            "Downloading roman-5.2-py3-none-any.whl (6.0 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Installing collected packages: roman, click, backports.functools-lru-cache, indic-transliteration\n",
            "\u001b[2K  Attempting uninstall: click\n",
            "\u001b[2K    Found existing installation: click 7.1.2\n",
            "\u001b[2K    Uninstalling click-7.1.2:\n",
            "\u001b[2K      Successfully uninstalled click-7.1.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [indic-transliteration]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "urduhack 1.0.3 requires Click~=7.1, but you have click 8.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backports.functools-lru-cache-2.0.0 click-8.3.1 indic-transliteration-2.3.75 roman-5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "import re\n",
        "\n",
        "# 1. Initialize your working LID model\n",
        "lid_pipeline = pipeline(\"token-classification\", model=\"l3cube-pune/hing-bert-lid\", device=0)\n",
        "\n",
        "def process_sentence_to_hindi(sentence):\n",
        "    # Detect language labels (HI, EN, etc.)\n",
        "    results = lid_pipeline(sentence)\n",
        "\n",
        "    # Reconstruct words from sub-tokens\n",
        "    words_data = []\n",
        "    current_word, current_label = \"\", \"\"\n",
        "    for entity in results:\n",
        "        raw_word = entity['word']\n",
        "        label = entity['entity']\n",
        "        if raw_word.startswith(\"##\"):\n",
        "            current_word += raw_word.replace(\"##\", \"\")\n",
        "        else:\n",
        "            if current_word: words_data.append((current_word, current_label))\n",
        "            current_word, current_label = raw_word, label\n",
        "    if current_word: words_data.append((current_word, current_label))\n",
        "\n",
        "    # 2. Extract Hindi words and convert to Devanagari\n",
        "    final_output = []\n",
        "    for word, label in words_data:\n",
        "        if label == 'HI':\n",
        "            # Clean non-alphabet characters\n",
        "            clean_word = re.sub(r'[^a-zA-Z]', '', word).lower()\n",
        "\n",
        "            if len(clean_word) > 0:\n",
        "                # Transliterate Roman to Devanagari\n",
        "                # We use ITRANS scheme for better accuracy with common Roman Hindi\n",
        "                hindi_script = transliterate(clean_word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "                final_output.append((clean_word, hindi_script))\n",
        "\n",
        "    return final_output\n",
        "\n",
        "# --- TEST ---\n",
        "sentence = \"Pahle toh hum baat karte hain Cambodian Civil War ki (999 words). Wahan par jo hua, woh sach mein heartache aur shok se bhara tha. Lakhon logon ki zindagiyan barbad ho gayihi. Kitni hi auraten vidhvaa ho gayihi, aur kitne bachche anath! Sab ke chehron par sirf nirasha aur melancholic hi nazar aata hoga us samay.\"\n",
        "results = process_sentence_to_hindi(sentence)\n",
        "\n",
        "\n",
        "for roman, script in results:\n",
        "    print(f\"roman:{roman:<15} hindi:{script}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJ2uj4tLi6x",
        "outputId": "b7eeb4c7-1650-4cc0-8b6e-bb579529c129"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roman:pahle           hindi:पह्ले\n",
            "roman:toh             hindi:तोह्\n",
            "roman:hum             hindi:हुम्\n",
            "roman:baat            hindi:बात्\n",
            "roman:karte           hindi:कर्ते\n",
            "roman:hain            hindi:हैन्\n",
            "roman:ki              hindi:कि\n",
            "roman:wahan           hindi:वहन्\n",
            "roman:par             hindi:पर्\n",
            "roman:jo              hindi:जो\n",
            "roman:hua             hindi:हुअ\n",
            "roman:woh             hindi:वोह्\n",
            "roman:sach            hindi:सच्\n",
            "roman:mein            hindi:मेइन्\n",
            "roman:aur             hindi:और्\n",
            "roman:shok            hindi:शोक्\n",
            "roman:se              hindi:से\n",
            "roman:bhara           hindi:भर\n",
            "roman:lakhon          hindi:लखोन्\n",
            "roman:logon           hindi:लोगोन्\n",
            "roman:ki              hindi:कि\n",
            "roman:zindagiyan      hindi:ज़िन्दगियन्\n",
            "roman:barbad          hindi:बर्बद्\n",
            "roman:ho              hindi:हो\n",
            "roman:gayihi          hindi:गयिहि\n",
            "roman:kitni           hindi:कित्नि\n",
            "roman:hi              hindi:हि\n",
            "roman:auraten         hindi:औरतेन्\n",
            "roman:vidhvaa         hindi:विध्वा\n",
            "roman:ho              hindi:हो\n",
            "roman:gayihi          hindi:गयिहि\n",
            "roman:aur             hindi:और्\n",
            "roman:kitne           hindi:कित्ने\n",
            "roman:bachche         hindi:बच्चे\n",
            "roman:anath           hindi:अनथ्\n",
            "roman:sab             hindi:सब्\n",
            "roman:ke              hindi:के\n",
            "roman:chehron         hindi:चेह्रोन्\n",
            "roman:par             hindi:पर्\n",
            "roman:sirf            hindi:सिर्फ़्\n",
            "roman:nirasha         hindi:निरश\n",
            "roman:aur             hindi:और्\n",
            "roman:hi              hindi:हि\n",
            "roman:nazar           hindi:नज़र्\n",
            "roman:aata            hindi:आत\n",
            "roman:hoga            hindi:होग\n",
            "roman:us              hindi:उस्\n",
            "roman:samay           hindi:समय्\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vLSYo8kmM24h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmudH_BcI-jq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cO_-Se-YLNwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}